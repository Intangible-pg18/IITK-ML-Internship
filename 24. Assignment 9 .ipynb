{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_9_prateek.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXmQGNBWwzS1"
      },
      "source": [
        "### Introduction\n",
        "- In this assignment, you will build a two layer neural network for classification from scratch using only numpy.\n",
        "- Please refer to videos on Backpropagation and one reference material shared in additional resources for the understanding required to solve this assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCZeHgK-xAy8"
      },
      "source": [
        "\"\"\" Some functions required for testing \"\"\"\n",
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_model(D, H, C):\n",
        "  il = keras.layers.Input(shape=(D,))\n",
        "  hl = keras.layers.Dense(H, activation = 'relu')(il)\n",
        "  ol = keras.layers.Dense(C, activation = 'softmax')(hl)\n",
        "  model = keras.models.Model(inputs = [il], outputs = [ol])\n",
        "\n",
        "  rng = np.random.RandomState(2020)\n",
        "  model.layers[1].set_weights([rng.rand(D * H).reshape(D, H), rng.rand(H, )])\n",
        "  model.layers[2].set_weights([rng.rand(H * C).reshape(H, C), rng.rand(C, )])\n",
        "  return model\n",
        "\n",
        "def create_inputs(N, D):\n",
        "  rng = np.random.RandomState(2020)\n",
        "  return rng.rand(N * D).reshape(N, D)\n",
        "\n",
        "def set_weights_from_model(tln, test_net):\n",
        "  tln.params['W1'] = test_net.layers[1].get_weights()[0]\n",
        "  tln.params['b1'] = test_net.layers[1].get_weights()[1]\n",
        "  tln.params['W2'] = test_net.layers[2].get_weights()[0]\n",
        "  tln.params['b2'] = test_net.layers[2].get_weights()[1]\n",
        "  return tln\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OoL62wOux9t"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class TwoLayerNet(object):\n",
        "    \"\"\"\n",
        "    A two-layer fully-connected neural network. The net has an input dimension of\n",
        "    D, a hidden layer dimension of H, and performs classification over C classes.\n",
        "    We train the network with a softmax loss function and L2 regularization on the\n",
        "    weight matrices. The network uses a ReLU nonlinearity after the first fully\n",
        "    connected layer.\n",
        "\n",
        "    In other words, the network has the following architecture:\n",
        "\n",
        "    input - fully connected layer - ReLU - fully connected layer - softmax\n",
        "\n",
        "    The outputs of the second fully-connected layer are the scores for each class.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, std=1e-4):\n",
        "        \"\"\"\n",
        "        Initialize the model. \n",
        "        Weights are initialized to small random values and\n",
        "        biases are initialized to zero. \n",
        "        Weights and biases are stored in the\n",
        "        variable self.params, which is a dictionary with the following keys:\n",
        "\n",
        "        W1: First layer weights; has shape (D, H)\n",
        "        b1: First layer biases; has shape (H,)\n",
        "        W2: Second layer weights; has shape (H, C)\n",
        "        b2: Second layer biases; has shape (C,)\n",
        "\n",
        "        Inputs:\n",
        "        - input_size: The dimension N of the input data.\n",
        "        - hidden_size: The number of neurons H in the hidden layer.\n",
        "        - output_size: The number of classes C.\n",
        "        \"\"\"\n",
        "        self.params = {}\n",
        "        D = input_size\n",
        "        H = hidden_size\n",
        "        C = output_size\n",
        "        self.params['W1'] = np.random.normal(0, std, D*H).reshape(D, H)\n",
        "        self.params['b1'] = np.zeros(H)\n",
        "        self.params['W2'] = np.random.normal(0, std, H*C).reshape(H, C)\n",
        "        self.params['b2'] = np.zeros(C)\n",
        "        ### Write your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9ScjBCeTwzS7",
        "outputId": "91a6bac5-a653-4c50-ea0e-d7c37e1d2a23"
      },
      "source": [
        "\"\"\" Test Cases for Initialization\"\"\"\n",
        "tln = TwoLayerNet(2, 3, 2)\n",
        "assert tln.params['W1'].shape == (2, 3)\n",
        "assert tln.params['b1'].shape == (3, )\n",
        "assert tln.params['W2'].shape == (3, 2)\n",
        "assert tln.params['b2'].shape == (2, )\n",
        "print('Test passed', '\\U0001F44D')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh8LRCT9voz1"
      },
      "source": [
        "class TwoLayerNet(TwoLayerNet):\n",
        "\n",
        "    def forward(self, X):\n",
        "      \"\"\"\n",
        "      Compute the output of a full forward pass of the network.\n",
        "      \n",
        "      First apply weights W1 and biases b1 on inputs and then apply relu non-linearity.\n",
        "      Then apply weights W2 and biases b2 on hidden layer values and then apply softmax non-linearity to get the output\n",
        "      \n",
        "      Inputs:\n",
        "      - X : Input data of shape (N, D). Each X[i] is a training sample\n",
        "      \n",
        "      Outputs:\n",
        "      - y_out : numpy array with Outputs of shape (N, C)\n",
        "      \n",
        "      \"\"\"\n",
        "      ### Write your code here\n",
        "      z1 = X@self.params['W1'] + self.params['b1']\n",
        "      a1 = np.maximum(z1, 0)\n",
        "      z2 = a1@self.params['W2'] + self.params['b2']\n",
        "      a2_num = np.e**(z2)\n",
        "      a2_denom = np.sum(a2_num, axis = 1)\n",
        "      a2 = np.zeros(a2_num.shape)\n",
        "      for i in range(z2.shape[0]):\n",
        "        a2[i, :] = a2_num[i, :] / a2_denom[i]\n",
        "      y_out = a2\n",
        "\n",
        "      return y_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rJeXhkRZwzTD",
        "outputId": "280dbae7-5dcc-4a3d-aa19-835b2e193ce0"
      },
      "source": [
        "\"\"\"Test Cases for Forward pass\"\"\"\n",
        "tln = TwoLayerNet(2, 4, 2)\n",
        "test_net = create_model(2, 4, 2)\n",
        "tln = set_weights_from_model(tln, test_net)\n",
        "X = create_inputs(4, 2)\n",
        "y_forward = tln.forward(X)\n",
        "assert y_forward.shape == (4, 2)\n",
        "assert np.all(np.isclose(y_forward, test_net.predict(X), atol = 0.0001))\n",
        "print('Test passed', '\\U0001F44D')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbOelhQCwzTH"
      },
      "source": [
        "class TwoLayerNet(TwoLayerNet):\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Use the trained weights of this two-layer network to predict labels for\n",
        "        data points. For each data point we predict scores for each of the C\n",
        "        classes, and assign each data point to the class with the highest score.\n",
        "\n",
        "        Inputs:\n",
        "        - X: A numpy array of shape (N, D) giving N D-dimensional data points to\n",
        "          classify.\n",
        "\n",
        "        Returns:\n",
        "        - y_pred: A numpy array of shape (N,) giving predicted labels for each of\n",
        "          the elements of X. For all i, y_pred[i] = c means that X[i] is predicted\n",
        "          to have class c, where 0 <= c < C.\n",
        "        \"\"\"\n",
        "        y_pred = None\n",
        "        y_out = self.forward(X)\n",
        "        y_pred = np.argmax(y_out, axis = 1)\n",
        "\n",
        "\n",
        "        ###########################################################################\n",
        "        # TODO: Implement this function; it should be VERY simple!                #\n",
        "        ###########################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        ### Write your code here\n",
        "        \n",
        "        return y_pred\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AAJuwv5bwzTK",
        "outputId": "7c19cb63-5437-4971-ee02-854bece7d4d7"
      },
      "source": [
        "\"\"\" Test Cases for predict\"\"\"\n",
        "tln = TwoLayerNet(2, 4, 2)\n",
        "test_net = create_model(2, 4, 2)\n",
        "tln = set_weights_from_model(tln, test_net)\n",
        "X = create_inputs(4, 2)\n",
        "y_pred = tln.predict(X)\n",
        "test_pred = np.argmax(test_net.predict(X), axis = 1)\n",
        "assert np.all(np.isclose(y_pred, test_pred, atol = 0.01))\n",
        "print('Test passed', '\\U0001F44D')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tabhV02TwzTO"
      },
      "source": [
        "#### Loss\n",
        "Note: <br>\n",
        "$L = -\\sum{t_i \\log{p_i}}$ <br>\n",
        "where $p_i$ is probability score predicted by model. <br>\n",
        "$t_i = 1$ for the true class $i$ and $t_i = 0$ for all other classes for a particular sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mO3-DSCwzTO"
      },
      "source": [
        "class TwoLayerNet(TwoLayerNet):    \n",
        "    def loss(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Compute the loss and gradients for a two layer fully connected neural\n",
        "        network.\n",
        "\n",
        "        Inputs:\n",
        "        - X: Input data of shape (N, D). Each X[i] is a training sample.\n",
        "        - y: Vector of training labels. y[i] is the label for X[i], and each y[i] is\n",
        "          an integer in the range 0 <= y[i] < C.\n",
        "\n",
        "\n",
        "        Returns:\n",
        "        If y is None, return a matrix scores of shape (N, C) where scores[i, c] is\n",
        "        the score for class c on input X[i].\n",
        "\n",
        "        If y is not None, instead return a tuple of:\n",
        "        - loss: Loss (data loss and regularization loss) for this batch of training\n",
        "          samples. (This is the mean loss over N samples)\n",
        "        - grads: Dictionary mapping parameter names to gradients of those parameters\n",
        "          with respect to the loss function; has the same keys as self.params.\n",
        "        \"\"\"\n",
        "        # Unpack variables from the params dictionary\n",
        "        W1, b1 = self.params['W1'], self.params['b1']\n",
        "        W2, b2 = self.params['W2'], self.params['b2']\n",
        "        N, D = X.shape\n",
        "        H, C = W2.shape\n",
        "        \n",
        "\n",
        "        # Compute the forward pass\n",
        "        scores = None\n",
        "        #############################################################################\n",
        "        # TODO: Perform the forward pass, computing the class scores for the input. #\n",
        "        # Store the result in the scores variable, which should be an array of      #\n",
        "        # shape (N, C).                                                             #\n",
        "        #############################################################################\n",
        "        \n",
        "      \n",
        "        # Compute the forward pass\n",
        "        \n",
        "        z1 = X@self.params['W1'] + self.params['b1']\n",
        "        a1 = np.maximum(z1, 0)\n",
        "        z2 = a1@self.params['W2'] + self.params['b2']\n",
        "        a2_num = np.e**(z2)\n",
        "        a2_denom = np.sum(a2_num, axis = 1)\n",
        "        a2 = np.zeros(a2_num.shape)\n",
        "        for i in range(z2.shape[0]):\n",
        "          a2[i, :] = a2_num[i, :] / a2_denom[i]\n",
        "        y_out = a2\n",
        "        scores = y_out\n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "        ## Write your code here\n",
        "        \n",
        "        \n",
        "        \n",
        "        # # Compute the loss\n",
        "        loss = None\n",
        "        loss_samples = np.zeros(N)\n",
        "        for i in range(N):\n",
        "          loss_samples[i] = -np.log(scores[i, y[i]])\n",
        "        loss = np.mean(loss_samples)\n",
        "        \n",
        "        #############################################################################\n",
        "        # TODO: Finish the forward pass, and compute the loss. This should include  #\n",
        "        # both the data loss and L2 regularization for W1 and W2. Store the result  #\n",
        "        # in the variable loss, which should be a scalar. Use the Categorical       #\n",
        "        # Cross Entropy loss.                                                       #\n",
        "        #############################################################################\n",
        "      \n",
        "        ### Write your code here\n",
        "        \n",
        "\n",
        "        # Backward pass: compute gradients\n",
        "        grads = {}\n",
        "\n",
        "        da2 = np.zeros((N, C))\n",
        "        for i in range(N):\n",
        "          da2[i, y[i]] = -1/a2[i, y[i]]\n",
        "        \n",
        "\n",
        "        da2_num = np.zeros((N, C))\n",
        "        da2_denom = np.zeros(N)\n",
        "        for i in range(N):\n",
        "          da2_num[i] = (1/a2_denom[i])*da2[i,: ]\n",
        "          da2_denom[i] = np.sum((-a2_num[i, :]/a2_denom[i]**2)*da2[i, :])\n",
        "\n",
        "        for i in range(N):\n",
        "          da2_num[i] += da2_denom[i]\n",
        "        \n",
        "        dz2 = a2_num * da2_num\n",
        "        da1 = dz2@self.params['W2'].T\n",
        "        dW2 = a1.T @ dz2\n",
        "        db2 = np.sum(dz2, axis = 0)\n",
        "        \n",
        "        \n",
        "        drelu = np.vectorize(lambda x: 1 if x>0 else 0)\n",
        "        dz1 = drelu(a1) * da1\n",
        "        dW1 = X.T @ dz1\n",
        "        db1 = np.sum(dz1, axis=0)\n",
        "\n",
        "        \n",
        "        #############################################################################\n",
        "        # TODO: Compute the backward pass, computing the derivatives of the weights #\n",
        "        # and biases. Store the results in the grads dictionary. For example,       #\n",
        "        # grads['W1'] should store the gradient on W1, and be a matrix of same size #\n",
        "        #############################################################################\n",
        "        ## We have to divide by N because aggregate loss = 1/N(Summation(-ti log yi))\n",
        "        grads['W1'] = dW1/N\n",
        "        grads['b1'] = db1/N\n",
        "        grads['W2'] = dW2/N\n",
        "        grads['b2'] = db2/N\n",
        "\n",
        "        ### Write your code here\n",
        "\n",
        "        return loss, grads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "zn1tAYrpwzTS",
        "outputId": "700c12db-8008-4f78-c456-c623bcc7b023"
      },
      "source": [
        "\"\"\" Tests for loss and gradient computation \"\"\"\n",
        "### First compute loss and gradients using keras\n",
        "model = create_model(2, 4, 2)\n",
        "X = create_inputs(4, 2)\n",
        "y = np.array([0, 1, 1, 0])\n",
        "y_onehot = keras.utils.to_categorical(y, 2)\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-3, momentum=0.0, nesterov=False, name=\"SGD\")\n",
        "loss_fn = keras.losses.CategoricalCrossentropy()\n",
        "batch_size = 4\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X, y_onehot))\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "epochs = 1\n",
        "for epoch in range(epochs):\n",
        "  for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_out = model(x_batch_train, training = True)\n",
        "\n",
        "      ## Compute loss value for this minibatch\n",
        "      loss_value = loss_fn(y_batch_train, y_out)\n",
        "    \n",
        "    grads_model = {}\n",
        "    grads_model['W1'], grads_model['b1'], grads_model['W2'], grads_model['b2'] = [dw.numpy() for dw in tape.gradient(loss_value, model.trainable_weights)]\n",
        "\n",
        "### Compute loss and gradients using TwoLayerNet\n",
        "tln = TwoLayerNet(2, 4, 2)\n",
        "tln = set_weights_from_model(tln, model)\n",
        "loss, grads_tln = tln.loss(X, y)\n",
        "\n",
        "#### Now match\n",
        "## Loss should be correctly computed\n",
        "assert np.isclose(loss, loss_value.numpy(), atol = 0.0001)\n",
        "\n",
        "## Gradients should be correctly computed\n",
        "print(grads_tln['W1'], grads_model['W1'])\n",
        "assert np.all(np.isclose(grads_tln['W1'], grads_model['W1'], atol = 0.0001))\n",
        "assert np.all(np.isclose(grads_tln['b1'], grads_model['b1'], atol = 0.0001))\n",
        "assert np.all(np.isclose(grads_tln['W2'], grads_model['W2'], atol = 0.0001))\n",
        "assert np.all(np.isclose(grads_tln['b2'], grads_model['b2'], atol = 0.0001))\n",
        "\n",
        "print('Test passed', '\\U0001F44D')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.0159359  -0.01363542 -0.01441477 -0.00818676]\n",
            " [-0.00592148  0.00506667  0.00535626  0.00304205]] [[ 0.01593591 -0.01363542 -0.01441477 -0.00818677]\n",
            " [-0.00592148  0.00506666  0.00535626  0.00304205]]\n",
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANJB4KJni0ME"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyIYI5btwzTV"
      },
      "source": [
        "class TwoLayerNet(TwoLayerNet):\n",
        "    def train(self, X, y, X_val, y_val,\n",
        "              learning_rate=1e-3, num_iters=100,\n",
        "              batch_size=200, verbose=False):\n",
        "        \"\"\"\n",
        "        Train this neural network using stochastic gradient descent.\n",
        "\n",
        "        Inputs:\n",
        "        - X: A numpy array of shape (N, D) giving training data.\n",
        "        - y: A numpy array f shape (N,) giving training labels; y[i] = c means that\n",
        "          X[i] has label c, where 0 <= c < C.\n",
        "        - X_val: A numpy array of shape (N_val, D) giving validation data.\n",
        "        - y_val: A numpy array of shape (N_val,) giving validation labels.\n",
        "        - learning_rate: Scalar giving learning rate for optimization.\n",
        "        - num_iters: Number of steps to take when optimizing.\n",
        "        - batch_size: Number of training examples to use per step.\n",
        "        \"\"\"\n",
        "        num_train = X.shape[0]\n",
        "        iterations_per_epoch = max(num_train / batch_size, 1)\n",
        "\n",
        "        # Use SGD to optimize the parameters in self.model\n",
        "        loss_history = []\n",
        "        train_acc_history = []\n",
        "        val_acc_history = []\n",
        "        \n",
        "        ## Create a copy of X and shuffle it\n",
        "        shuffled_indices = np.arange(X.shape[0])\n",
        "        np.random.shuffle(shuffled_indices)\n",
        "        dataset_size = X.shape[0]\n",
        "        X_shuffled = X[shuffled_indices]\n",
        "        y_shuffled = y[shuffled_indices]\n",
        "\n",
        "        for it in range(num_iters):\n",
        "\n",
        "            #########################################################################\n",
        "            # TODO: Create a random minibatch of training data and labels, storing  #\n",
        "            # them in X_batch and y_batch respectively.                             #\n",
        "            #########################################################################\n",
        "\n",
        "            \n",
        "            ### Write your code here\n",
        "\n",
        "            start = (num_iters * batch_size)%dataset_size\n",
        "            X_batch = X_shuffled[start: start + batch_size]\n",
        "            y_batch = y_shuffled[start: start + batch_size]\n",
        "\n",
        "            \n",
        "            \n",
        "            # Compute loss and gradients using the current minibatch\n",
        "            loss, grads = self.loss(X_batch, y=y_batch)\n",
        "            loss_history.append(loss)\n",
        "\n",
        "            #########################################################################\n",
        "            # TODO: Use the gradients in the grads dictionary to update the         #\n",
        "            # parameters of the network (stored in the dictionary self.params)      #\n",
        "            # using stochastic gradient descent. You'll need to use the gradients   #\n",
        "            # stored in the grads dictionary defined above.                         #\n",
        "            #########################################################################\n",
        "\n",
        "            \n",
        "            ### Write your code here\n",
        "            self.params['W1'] -= learning_rate * grads['W1']\n",
        "            self.params['W2'] -= learning_rate * grads['W2']\n",
        "            self.params['b1'] -= learning_rate * grads['b1']\n",
        "            self.params['b2'] -= learning_rate * grads['b2']\n",
        "               \n",
        "\n",
        "            # Every epoch, check train and val accuracy\n",
        "            if it % iterations_per_epoch == 0:\n",
        "                # Check accuracy\n",
        "                train_acc = (self.predict(X_batch) == y_batch).mean()\n",
        "                val_acc = (self.predict(X_val) == y_val).mean()\n",
        "                train_acc_history.append(train_acc)\n",
        "                val_acc_history.append(val_acc)\n",
        "\n",
        "                # Decay learning rate\n",
        "                # learning_rate *= learning_rate_decay\n",
        "\n",
        "        return {\n",
        "          'loss_history': loss_history,\n",
        "          'train_acc_history': train_acc_history,\n",
        "          'val_acc_history': val_acc_history,\n",
        "        }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYEfUA1nmCju"
      },
      "source": [
        "### Using these networks on datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsACefMSmFX0"
      },
      "source": [
        "### XOR\n",
        "Use TwoLayerNet to train the XOR function discussed in the class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "MeUsLKYEwzTY",
        "outputId": "4881c4ca-45fa-446c-8019-10a697011d5c"
      },
      "source": [
        "### Write your code here\n",
        "X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_xor = np.array([0, 1, 1, 0])\n",
        "xor_net = TwoLayerNet(2, 5, 2)\n",
        "h = xor_net.train(X_xor, y_xor, X_xor, y_xor, batch_size = 4, num_iters = 20000, learning_rate = 0.01)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(h['loss_history'])\n",
        "print(h['loss_history'][-10:])\n",
        "xor_net.predict(X_xor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.015224412103666787, 0.015220327333498934, 0.015219150040967182, 0.015215483459458005, 0.015211298510849368, 0.015212186031203945, 0.015210368255511048, 0.015209635783566964, 0.015205565909866313, 0.015201384785027024]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "aPdW_QssjHzO",
        "outputId": "b29b8e1b-7b4d-4146-ffc8-2a8165734c62"
      },
      "source": [
        "plt.plot(h['val_acc_history'])\n",
        "h['val_acc_history'][-10:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3D4GjcImFbW"
      },
      "source": [
        "### Iris\n",
        "Use TwoLayerNet to train the iris dataset. Choose 120 samples randomly for training and the rest for testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "jSjLcJT1mX-9",
        "outputId": "a213bbc7-1137-4b10-8bdd-dfa398528afb"
      },
      "source": [
        "### Write your code here\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "random_indices = np.arange(150)\n",
        "np.random.shuffle(random_indices)\n",
        "X_iris = iris['data'][random_indices[:120]]\n",
        "y_iris = iris['target'][random_indices[:120]]\n",
        "X_iris_val = iris['data'][random_indices[120:]]\n",
        "y_iris_val = iris['target'][random_indices[120:]]\n",
        "iris_net = TwoLayerNet(4, 64, 3)\n",
        "h = iris_net.train(X_iris, y_iris, X_iris_val, y_iris_val, num_iters = 1000, batch_size = 20, learning_rate = 0.05)\n",
        "plt.plot(h['loss_history'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fab88167860>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "B-eSD5PUl6hD",
        "outputId": "c37cfb21-0560-46d6-d8ea-fb1d2bcdfe6d"
      },
      "source": [
        "plt.plot(h['val_acc_history'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fab88270978>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbFD9EXlmaDI"
      },
      "source": [
        "### Advanced\n",
        "Add weight regularization to the loss and rewrite backprop part of TwoLayerNet. <br>\n",
        "Train using some datasets and see if regularized network performs better than its older counterpart.\n",
        "<br>\n",
        "The expression for loss with regularization is as follows - <br>\n",
        "$L = -\\sum{t_i \\log{p_i}} + \\lambda(|w_1|^2 + |w_2|^2)$ <br>\n",
        "$\\lambda$ is a tunable hyper-parameter  denoting strength of regularization. <br>\n",
        "If it is too high, network will struggle to fit, and if it is too low, network will overfit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBAJhyB9oB8M"
      },
      "source": [
        "### Write your code here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}